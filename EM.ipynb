{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df8ea0-a55a-4d75-91ac-908798a2a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_federated==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a26ad-73b9-4cb4-99a3-312c6b2edd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf0442-117c-4628-b835-83e1aae883d4",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuBEohAoV3Te"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Use the %tensorflow_version magic if in colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716e8fe-89c2-4cb5-93c6-4cd3ea71b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os,random\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"THEANO_FLAGS\"]  = \"device=cpu\"\n",
    "import numpy as np\n",
    "import theano as th\n",
    "import theano.tensor as T\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import adam\n",
    "import matplotlib.pypl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23128b-d8e1-4990-ae37-b2174f401efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle as cPickle  # Python3 uses 'pickle' for the 'cPickle' module from Python2\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from the pickle file\n",
    "# Make sure the RML2016.10a_dict.pkl file is downloaded and extracted\n",
    "# from https://www.deepsig.io/datasets. Adjust the file path as needed.\n",
    "file_path = \"RML2016.10a_dict.pkl\"\n",
    "\n",
    "# Since the pickle file was created in Python2, specify encoding='latin1' to handle it in Python3\n",
    "with open(file_path, 'rb') as f:\n",
    "    Xd = cPickle.load(f, encoding=\"latin1\") \n",
    "\n",
    "# Extract unique SNRs (Signal-to-Noise Ratios) and modulation schemes from dataset keys\n",
    "snrs, mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1, 0])\n",
    "\n",
    "# Initialize lists to store data (X) and corresponding labels (modulation scheme, SNR)\n",
    "X = []\n",
    "lbl = []\n",
    "\n",
    "# Iterate over each modulation scheme and SNR\n",
    "for mod in mods:\n",
    "    for snr in snrs:\n",
    "        # Append the signal data (features) for the current modulation scheme and SNR\n",
    "        X.append(Xd[(mod, snr)])\n",
    "        \n",
    "        # Append the corresponding label (modulation scheme, SNR) for each signal\n",
    "        for i in range(Xd[(mod, snr)].shape[0]):\n",
    "            lbl.append((mod, snr))\n",
    "\n",
    "# Stack the list of arrays vertically to create a single feature array\n",
    "X = np.vstack(X)\n",
    "\n",
    "# The final arrays: \n",
    "# X contains the signal data, and lbl contains the labels (mod, SNR) for each signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b74682-0d16-4ae4-8487-218e708f147e",
   "metadata": {},
   "source": [
    "Let's break this code down thoroughly.\n",
    "\n",
    "### Objective:\n",
    "This part of the code is focused on extracting and organizing **modulation schemes**, **Signal-to-Noise Ratios (SNRs)**, and **signal data** from a dataset that is structured as a dictionary `Xd`. The goal is to:\n",
    "- Extract unique modulation schemes and SNRs from the dataset keys.\n",
    "- Organize signal data (`X`) and their corresponding labels (`lbl`) into arrays.\n",
    "\n",
    "### Step-by-Step Breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Extract Unique SNRs and Modulation Schemes**\n",
    "\n",
    "#### Code:\n",
    "```python\n",
    "snrs, mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1, 0])\n",
    "```\n",
    "\n",
    "This single line extracts **unique SNR values** and **modulation schemes** from the keys of the dataset dictionary `Xd`. Here's a detailed explanation:\n",
    "\n",
    "#### **Key Concepts**:\n",
    "- **`Xd.keys()`**: \n",
    "  The dataset `Xd` is a Python dictionary where the keys are tuples in the format `(modulation_scheme, SNR)`. For example:\n",
    "  ```python\n",
    "  Xd.keys() -> [('BPSK', -10), ('BPSK', 0), ('QPSK', 10), ...]\n",
    "  ```\n",
    "  The key pairs `(modulation_scheme, SNR)` represent unique combinations of modulation schemes (such as BPSK, QPSK, etc.) and SNR values (such as -10, 0, 10, etc.). The values in `Xd` are arrays containing signal data for each modulation scheme and SNR combination.\n",
    "\n",
    "#### **How the Code Works**:\n",
    "- **`map(lambda j: ...)`**:\n",
    "  The `map()` function is applied to extract both **SNR values** and **modulation schemes**:\n",
    "  - **When `j = 1`**, it extracts the **SNR values** (from the second element of the tuple).\n",
    "  - **When `j = 0`**, it extracts the **modulation schemes** (from the first element of the tuple).\n",
    "  \n",
    "- **`map(lambda x: x[j], Xd.keys())`**:\n",
    "  This part of the code maps over the keys of `Xd` (which are tuples like `('BPSK', -10)`), and retrieves the **SNR** (when `j = 1`) or the **modulation scheme** (when `j = 0`).\n",
    "  - Example for **SNR**: Extracting the second element (SNR) from each tuple: `[-10, 0, 10, ...]`.\n",
    "  - Example for **modulation scheme**: Extracting the first element (modulation scheme) from each tuple: `['BPSK', 'QPSK', ...]`.\n",
    "\n",
    "- **`set()`**: \n",
    "  The extracted values are converted into a **set** to remove duplicates, ensuring that only unique modulation schemes and SNR values are captured.\n",
    "\n",
    "- **`sorted()`**: \n",
    "  The list of unique modulation schemes and SNR values is sorted to ensure they are in ascending order.\n",
    "\n",
    "- **`map(..., [1, 0])`**: \n",
    "  This part indicates that the `map` function is applied twice:\n",
    "    - First, it extracts and sorts **SNR values** (when `j = 1`).\n",
    "    - Second, it extracts and sorts **modulation schemes** (when `j = 0`).\n",
    "\n",
    "### Final Result:\n",
    "- **`snrs`**: A sorted list of unique SNR values.\n",
    "- **`mods`**: A sorted list of unique modulation schemes.\n",
    "\n",
    "### Example:\n",
    "- If `Xd.keys()` contains:\n",
    "  ```python\n",
    "  [('BPSK', -10), ('BPSK', 0), ('QPSK', 10), ('QPSK', -10)]\n",
    "  ```\n",
    "  Then the output would be:\n",
    "  - `mods = ['BPSK', 'QPSK']`\n",
    "  - `snrs = [-10, 0, 10]`\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Initialize Empty Lists for Data and Labels**\n",
    "\n",
    "#### Code:\n",
    "```python\n",
    "X = []\n",
    "lbl = []\n",
    "```\n",
    "\n",
    "- **`X`**: This empty list will store the **signal data** (features) for all modulation schemes and SNR values.\n",
    "- **`lbl`**: This empty list will store the **corresponding labels** for each signal in `X`. Each label will be a tuple `(modulation_scheme, SNR)`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Iterate Over Each Modulation Scheme and SNR**\n",
    "\n",
    "#### Code:\n",
    "```python\n",
    "for mod in mods:\n",
    "    for snr in snrs:\n",
    "```\n",
    "\n",
    "- This **nested loop** iterates over all combinations of **modulation schemes** (`mods`) and **SNR values** (`snrs`).\n",
    "\n",
    "    - **Outer loop**: `mod` takes each modulation scheme from `mods` (e.g., 'BPSK', 'QPSK', etc.).\n",
    "    - **Inner loop**: `snr` takes each SNR value from `snrs` (e.g., -10, 0, 10, etc.).\n",
    "\n",
    "For each combination `(mod, snr)`, the corresponding **signal data** is extracted, and labels are created.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Append Signal Data and Labels**\n",
    "\n",
    "#### Code:\n",
    "```python\n",
    "# Append the signal data (features) for the current modulation scheme and SNR\n",
    "X.append(Xd[(mod, snr)])\n",
    "\n",
    "# Append the corresponding label (modulation scheme, SNR) for each signal\n",
    "for i in range(Xd[(mod, snr)].shape[0]):\n",
    "    lbl.append((mod, snr))\n",
    "```\n",
    "\n",
    "#### **Appending Signal Data**:\n",
    "- **`Xd[(mod, snr)]`**:\n",
    "  This retrieves the signal data from the dataset `Xd` for the current modulation scheme (`mod`) and SNR (`snr`). The signal data is stored as a **numpy array**, where:\n",
    "  - The first dimension of the array represents different signals (examples) for the `(mod, snr)` pair.\n",
    "  - The next dimensions represent the signal's features (such as I/Q components with time samples).\n",
    "\n",
    "  For example:\n",
    "  ```python\n",
    "  Xd[('BPSK', 0)] -> numpy array with shape (N, 2, 128)\n",
    "  ```\n",
    "  Here, `N` is the number of signals (examples) with modulation scheme `BPSK` and SNR `0`.\n",
    "\n",
    "- **`X.append(Xd[(mod, snr)])`**:\n",
    "  This appends the entire numpy array for the current `(mod, snr)` pair to the list `X`. Each appended element is a 3D array of signal data with shape `(N, 2, 128)`.\n",
    "\n",
    "#### **Appending Labels**:\n",
    "- **`Xd[(mod, snr)].shape[0]`**:\n",
    "  This gives the number of signals (examples) in the numpy array for the current `(mod, snr)` pair. Let's call this `N`.\n",
    "\n",
    "- **Labeling Process**:\n",
    "  For each signal (row) in the array `Xd[(mod, snr)]`, the tuple `(mod, snr)` is appended to the list `lbl`:\n",
    "  ```python\n",
    "  for i in range(N):\n",
    "      lbl.append((mod, snr))\n",
    "  ```\n",
    "  This loop runs `N` times, where `N` is the number of signals in `Xd[(mod, snr)]`. Each signal is assigned the label `(mod, snr)`.\n",
    "\n",
    "### Example:\n",
    "Suppose there are 100 signals in `Xd[('BPSK', 0)]`, the loop will append the label `('BPSK', 0)` 100 times to `lbl`, corresponding to each of those 100 signals.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Stack the List of Arrays Vertically**\n",
    "\n",
    "#### Code:\n",
    "```python\n",
    "X = np.vstack(X)\n",
    "```\n",
    "\n",
    "At this point:\n",
    "- **`X`** is a list of 3D arrays, where each array represents the signal data for a specific modulation scheme and SNR (e.g., `Xd[('BPSK', 0)]`).\n",
    "\n",
    "- **`np.vstack(X)`**:\n",
    "  - This function stacks all the 3D arrays from the list `X` **vertically**, creating a single large 3D numpy array.\n",
    "  - After stacking, the final `X` becomes a single numpy array where:\n",
    "    - The first dimension is the total number of signals (rows).\n",
    "    - The second and third dimensions are the features of each signal (e.g., `(2, 128)` for I/Q samples).\n",
    "\n",
    "### Example:\n",
    "Let’s assume:\n",
    "- `X` contains 3 arrays:\n",
    "  - An array of shape `(100, 2, 128)` for `('BPSK', 0)`.\n",
    "  - An array of shape `(150, 2, 128)` for `('QPSK', 0)`.\n",
    "  - An array of shape `(200, 2, 128)` for `('8PSK', 10)`.\n",
    "\n",
    "After stacking, `X` will have the shape:\n",
    "```python\n",
    "X.shape -> (450, 2, 128)\n",
    "```\n",
    "Where 450 is the total number of signals (100 + 150 + 200).\n",
    "\n",
    "---\n",
    "\n",
    "### Final Arrays:\n",
    "\n",
    "- **`X`**:\n",
    "  - A 3D numpy array where each signal is represented by its features (e.g., I/Q components with 128 time samples).\n",
    "  - Shape: `(total_signals, 2, 128)`, where `total_signals` is the total number of signals across all modulation schemes and SNRs.\n",
    "\n",
    "- **`lbl`**:\n",
    "\n",
    "  - A list of tuples `(mod, snr)`, where each tuple represents the modulation scheme and SNR for the corresponding signal in `X`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e5046-4e70-448d-a721-c939d254e89b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1587028815337,
     "user": {
      "displayName": "MAJEED UMER[학생](대학원 컴퓨터공학과) ‍",
      "photoUrl": "",
      "userId": "09904507153320373005"
     },
     "user_tz": -540
    },
    "id": "wDYkJjUnmWZw",
    "outputId": "d4b43883-5fa5-41f9-f94a-8f4aff8f63b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220000"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe9073-6ecc-4dd2-be64-0be912b25c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the dataset into training and test sets\n",
    "# Ensuring that SNR and modulation labels are maintained for each sample\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "# Determine the total number of examples\n",
    "n_examples = X.shape[0]\n",
    "\n",
    "# Take 75% of the samples for training\n",
    "n_train = int(n_examples * 0.75)\n",
    "\n",
    "# Randomly select indices for the training set (without replacement)\n",
    "train_idx = np.random.choice(range(0, n_examples), size=n_train, replace=False)\n",
    "\n",
    "# The test set indices are the remaining samples\n",
    "test_idx = list(set(range(0, n_examples)) - set(train_idx))\n",
    "\n",
    "# Split the feature data into training and test sets\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "\n",
    "# Function to convert labels to one-hot encoding\n",
    "# 'yy' is a list of labels that gets transformed into a one-hot encoded matrix\n",
    "def to_onehot(yy):\n",
    "    data = list(yy)\n",
    "    yy1 = np.zeros([len(data), max(data) + 1])\n",
    "    yy1[np.arange(len(data)), data] = 1\n",
    "    return yy1\n",
    "\n",
    "# Convert training labels to one-hot encoding\n",
    "# The labels are based on the modulation scheme index corresponding to the training indices\n",
    "Y_train = to_onehot(map(lambda x: mods.index(lbl[x][0]), train_idx))\n",
    "\n",
    "# Convert test labels to one-hot encoding using the same logic\n",
    "Y_test = to_onehot(map(lambda x: mods.index(lbl[x][0]), test_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab9530-6ec9-47ef-bf6b-8b02c524fc0e",
   "metadata": {},
   "source": [
    "Let's break down the line `Y_train = to_onehot(map(lambda x: mods.index(lbl[x][0]), train_idx))` in detail:\n",
    "\n",
    "### 1. **Purpose**:\n",
    "The goal of this line is to create the one-hot encoded labels for the training data (`Y_train`). Each label represents the modulation scheme for the corresponding signal in `X_train`.\n",
    "\n",
    "### 2. **Understanding the Components**:\n",
    "\n",
    "#### `map(lambda x: mods.index(lbl[x][0]), train_idx)`:\n",
    "- **`train_idx`**: \n",
    "  This is the list of indices that have been randomly selected for the training set from the entire dataset. Each index points to a specific sample in the dataset.\n",
    "  \n",
    "- **`lbl`**: \n",
    "  This list holds the original labels in the form `(modulation_scheme, SNR)` for each signal in the dataset. So, `lbl[x]` is the label for the sample at index `x`, and `lbl[x][0]` extracts the modulation scheme for that sample.\n",
    "\n",
    "- **`mods.index(lbl[x][0])`**: \n",
    "  - `lbl[x][0]` extracts the modulation scheme from the label at index `x`. \n",
    "  - `mods` is a list of all modulation schemes (e.g., `['BPSK', 'QPSK', '8PSK', ...]`), and `mods.index(lbl[x][0])` finds the **index** of the modulation scheme in the `mods` list. This transforms the modulation scheme (a string) into a numerical label.\n",
    "\n",
    "- **`lambda x: mods.index(lbl[x][0])`**: \n",
    "  This is an anonymous function (using the `lambda` keyword) that takes an index `x`, finds the corresponding modulation scheme from `lbl[x][0]`, and returns the **index** of that modulation scheme from the `mods` list.\n",
    "\n",
    "- **`map(lambda x: mods.index(lbl[x][0]), train_idx)`**: \n",
    "  The `map` function applies the `lambda` function to each index in `train_idx`. For each index `x`, it retrieves the modulation scheme for the corresponding sample in the dataset, converts it to its numerical index, and returns these indices as a map object (which behaves like a list in Python 3).\n",
    "\n",
    "### 3. **`to_onehot()` Function**:\n",
    "- The `to_onehot()` function takes a list of numerical labels (the output of the `map()` function) and converts them into a **one-hot encoded** matrix. \n",
    "  - One-hot encoding is a way of representing categorical labels where each category (in this case, modulation scheme) is represented as a binary vector.\n",
    "  - For example, if there are 5 modulation schemes, a label `2` will be represented as `[0, 0, 1, 0, 0]`.\n",
    "\n",
    "#### Inside `to_onehot()`:\n",
    "- It creates a 2D array (`yy1`) with the number of rows equal to the number of labels (one row per sample) and the number of columns equal to the number of classes (one column for each modulation scheme).\n",
    "- It uses `np.arange()` to get a list of row indices and assigns a value of `1` to the corresponding column index (the modulation scheme) in each row.\n",
    "\n",
    "### Putting it all together:\n",
    "- **Step 1**: The `map(lambda x: mods.index(lbl[x][0]), train_idx)` transforms the list of training indices (`train_idx`) into a list of **numerical indices** representing the modulation scheme for each training sample.\n",
    "- **Step 2**: The `to_onehot()` function takes that list of modulation indices and converts it into a **one-hot encoded matrix**, where each row corresponds to a training sample, and the columns represent the modulation schemes.\n",
    "\n",
    "### Example:\n",
    "- Suppose `train_idx = [10, 20, 30]`, and the corresponding modulation schemes for these samples are `QPSK`, `BPSK`, and `8PSK`.\n",
    "- The `map()` function transforms these schemes into their numerical indices based on their position in `mods`, e.g., `[1, 0, 2]`.\n",
    "- The `to_onehot()` function will convert these indices into a one-hot encoded array:\n",
    "  ```\n",
    "  [[0, 1, 0],  # QPSK (index 1)\n",
    "   [1, 0, 0],  # BPSK (index 0)\n",
    "   [0, 0, 1]]  # 8PSK (index 2)\n",
    "  ```\n",
    "\n",
    "### Final Output:\n",
    "`Y_train` will be a matrix where each row is a one-hot encoded vector representing the modulation scheme for the corresponding training sample in `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ef982-32c7-4c07-a5ea-911d7dcf01ae",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gWCmEb_jJ1k"
   },
   "outputs": [],
   "source": [
    "in_shp = list(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb173c-3682-4d49-812b-58d34e8524d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1587028817505,
     "user": {
      "displayName": "MAJEED UMER[학생](대학원 컴퓨터공학과) ‍",
      "photoUrl": "",
      "userId": "09904507153320373005"
     },
     "user_tz": -540
    },
    "id": "TQl_hZF6jN3L",
    "outputId": "e355bc6b-b993-46d9-e699-9837b93e54b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 2, 128) [2, 128]\n"
     ]
    }
   ],
   "source": [
    "print (X_test.shape, in_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba394c-b9b6-47d6-9fc9-63a6d5767ba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1587028817877,
     "user": {
      "displayName": "MAJEED UMER[학생](대학원 컴퓨터공학과) ‍",
      "photoUrl": "",
      "userId": "09904507153320373005"
     },
     "user_tz": -540
    },
    "id": "XJ4tNg7hmFhQ",
    "outputId": "1669b22b-52d3-45cb-fc19-36d1648d9d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165000, 2, 128) [2, 128]\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, in_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37a874-d92e-48f9-859a-f743249d1aeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1587028818977,
     "user": {
      "displayName": "MAJEED UMER[학생](대학원 컴퓨터공학과) ‍",
      "photoUrl": "",
      "userId": "09904507153320373005"
     },
     "user_tz": -540
    },
    "id": "vjGBj_RUJTRH",
    "outputId": "077b7a88-97f6-4828-f031-fcb5979709be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f29f9-27ef-4d36-84d6-48f877b91a2f",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3r7CmNUTb9x"
   },
   "outputs": [],
   "source": [
    "Y_train=Y_train.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253b3be-8764-45e0-a4da-716930d1e0e1",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A699FToKTcLM"
   },
   "outputs": [],
   "source": [
    "Y_test=Y_test.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d37285-7909-41f6-bd9d-c9f3047d5e3b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcP6bFS7TdHE"
   },
   "outputs": [],
   "source": [
    "total_train=len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea97fdc-501e-4f9e-9328-5b27da141d15",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFqZolJ-jQni"
   },
   "outputs": [],
   "source": [
    "classes = mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257055b9-9cfb-4efc-9ce1-c6cb4205fa48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5402,
     "status": "ok",
     "timestamp": 1588141274921,
     "user": {
      "displayName": "MAJEED UMER[학생](대학원 컴퓨터공학과) ‍",
      "photoUrl": "",
      "userId": "09904507153320373005"
     },
     "user_tz": -540
    },
    "id": "sVQ-zf85jSoR",
    "outputId": "2453befe-919b-404c-de20-c0dbfbcc8245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8PSK',\n",
       " 'AM-DSB',\n",
       " 'AM-SSB',\n",
       " 'BPSK',\n",
       " 'CPFSK',\n",
       " 'GFSK',\n",
       " 'PAM4',\n",
       " 'QAM16',\n",
       " 'QAM64',\n",
       " 'QPSK',\n",
       " 'WBFM']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16da4ee-46df-4528-9333-c488c0b582bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e10025-6508-4623-8af0-8decb1dbef80",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdjB0FrpVGa6"
   },
   "outputs": [],
   "source": [
    "CLIENTS=3\n",
    "BATCH_SIZE_train = int(total_train/3) \n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1279b8e-609c-43ae-bbeb-b1c5e421c8ab",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-ShVVPyVlAz"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3f5f2-c631-4ed5-9567-131ab9129bd3",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALbjW1EyVX8z"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(X_train, Y_train, random_state=1000)\n",
    "x_test, y_test = shuffle(X_test, Y_test, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2d4b0-8c4c-4c54-b8bc-35f9831439b6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nm6oAZFQVnHI"
   },
   "outputs": [],
   "source": [
    "def generate_clients_datasets(n, BATCH_SIZE_EXT, source_x, source_y):\n",
    "    clients_dataset=[]\n",
    "    for i in range(n):\n",
    "        dataset=tf.data.Dataset.from_tensor_slices((source_x[i*BATCH_SIZE_EXT:(i+1)*BATCH_SIZE_EXT], source_y[i*BATCH_SIZE_EXT:(i+1)*BATCH_SIZE_EXT]))\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "        clients_dataset.append(dataset)\n",
    "    return clients_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c315bc9-c8f8-4459-8b69-2d60e9fdfc67",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5Bna7mxVvVa"
   },
   "outputs": [],
   "source": [
    "train_dataset_individual=generate_clients_datasets(CLIENTS, BATCH_SIZE_train, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf447b-5b64-40f0-9b42-bdcb571413dc",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsdOkMzaWZXW"
   },
   "outputs": [],
   "source": [
    "test_dataset_central=generate_clients_datasets(1, len(x_test), x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b167afa-6868-43d0-9b7d-5f06b1e0412c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlcVYWaKWf6_"
   },
   "outputs": [],
   "source": [
    "Epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf3cb0-c298-4589-9bc5-714dbdf767d4",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwGws6FrWiml"
   },
   "outputs": [],
   "source": [
    "federated_data=train_dataset_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341c392-0ff3-42f6-997b-68c255cf229b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMhtZFuSWmAX"
   },
   "outputs": [],
   "source": [
    "batch_of_samples = tf.nest.map_structure(\n",
    "    lambda x: x.numpy(), iter(train_dataset_individual[0]).next()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79d006-2507-462d-86d3-0254b42785d7",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzDv2_dObFZN"
   },
   "outputs": [],
   "source": [
    "dr = 0.2 # dropout rate (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384897fe-3934-4070-8b45-400701cd04b3",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3q-FpXdmv7h"
   },
   "outputs": [],
   "source": [
    "def model_instance_1():\n",
    "    \"\"\"Instantiates the keras model.\"\"\"\n",
    "    federated_model = tf.keras.models.Sequential([\n",
    "                                                  \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(128,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (2, 3), strides=1, padding=\"valid\", input_shape=(1, 2, 128), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "      \n",
    "    ])\n",
    "    federated_model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return tff.learning.from_compiled_keras_model(federated_model, batch_of_samples)\n",
    "\n",
    "federated_learning_iterative_process_1 = tff.learning.build_federated_averaging_process(\n",
    "    model_instance_1\n",
    ")\n",
    "\n",
    "state_1 = federated_learning_iterative_process_1.initialize()\n",
    "\n",
    "evaluation_1 = tff.learning.build_federated_evaluation(model_instance_1)\n",
    "\n",
    "federated_model_1 = tf.keras.models.Sequential([\n",
    "                                                  \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(128,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (2, 3), strides=1, padding=\"valid\", input_shape=(1, 2, 128), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee1e6c-202b-416f-8c57-f75f2479eded",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAv9dFP5XBzw"
   },
   "outputs": [],
   "source": [
    "def model_instance_2():\n",
    "    \"\"\"Instantiates the keras model.\"\"\"\n",
    "    federated_model = tf.keras.models.Sequential([\n",
    "                                                  \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(192,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (2, 3), strides=1, padding=\"valid\", input_shape=(1, 2, 128), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "      \n",
    "    ])\n",
    "    federated_model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return tff.learning.from_compiled_keras_model(federated_model, batch_of_samples)\n",
    "\n",
    "federated_learning_iterative_process_2 = tff.learning.build_federated_averaging_process(\n",
    "    model_instance_2\n",
    ")\n",
    "\n",
    "state_2 = federated_learning_iterative_process_2.initialize()\n",
    "\n",
    "evaluation_2 = tff.learning.build_federated_evaluation(model_instance_2)\n",
    "\n",
    "federated_model_2 = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(192,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (2, 3), strides=1, padding=\"valid\", input_shape=(1, 2, 128), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "      \n",
    "      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda31f1-0465-4085-8562-9c0d1c92c89c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1L1ckdEynFZv"
   },
   "outputs": [],
   "source": [
    "def model_instance_3():\n",
    "    \"\"\"Instantiates the keras model.\"\"\"\n",
    "    federated_model = tf.keras.models.Sequential([\n",
    "                                                  \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(256,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(80, (2, 3), strides=1, padding=\"valid\", input_shape=(1, 2, 128), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "      \n",
    "    ])\n",
    "    federated_model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return tff.learning.from_compiled_keras_model(federated_model, batch_of_samples)\n",
    "\n",
    "federated_learning_iterative_process_3 = tff.learning.build_federated_averaging_process(\n",
    "    model_instance_3\n",
    ")\n",
    "\n",
    "state_3 = federated_learning_iterative_process_3.initialize()\n",
    "\n",
    "evaluation_3 = tff.learning.build_federated_evaluation(model_instance_3)\n",
    "\n",
    "federated_model_3 = tf.keras.models.Sequential([\n",
    "                                                  \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(256,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(80, (2, 3), strides=1, padding=\"valid\", input_shape=(1, 2, 128), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88423801-ba42-43d1-a969-2bb7e803db35",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJIiukQNnZjI"
   },
   "outputs": [],
   "source": [
    "def model_instance_4():\n",
    "    \"\"\"Instantiates the keras model.\"\"\"\n",
    "    federated_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64,( 2, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (1, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "      \n",
    "    ])\n",
    "    federated_model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return tff.learning.from_compiled_keras_model(federated_model, batch_of_samples)\n",
    "\n",
    "federated_learning_iterative_process_4 = tff.learning.build_federated_averaging_process(\n",
    "    model_instance_4\n",
    ")\n",
    "\n",
    "state_4 = federated_learning_iterative_process_4.initialize()\n",
    "\n",
    "evaluation_4 = tff.learning.build_federated_evaluation(model_instance_4)\n",
    "\n",
    "federated_model_4 = tf.keras.models.Sequential([\n",
    "                                              \n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64,( 2, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (1, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "    \n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc74339-0a9b-4512-a4a5-c25446c11de5",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2MAegKunnl6"
   },
   "outputs": [],
   "source": [
    "def model_instance_5():\n",
    "    \"\"\"Instantiates the keras model.\"\"\"\n",
    "    federated_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(128,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(128,( 2, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (1, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])\n",
    "    federated_model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    return tff.learning.from_compiled_keras_model(federated_model, batch_of_samples)\n",
    "\n",
    "federated_learning_iterative_process_5 = tff.learning.build_federated_averaging_process(\n",
    "    model_instance_5\n",
    ")\n",
    "\n",
    "state_5 = federated_learning_iterative_process_5.initialize()\n",
    "\n",
    "evaluation_5 = tff.learning.build_federated_evaluation(model_instance_5)\n",
    "\n",
    "federated_model_5 = tf.keras.models.Sequential([\n",
    "\n",
    "    tf.keras.layers.Input(shape=(2,128)), \n",
    "    tf.keras.layers.Reshape(( 2, 128,1)),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(128,( 1, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(128,( 2, 3), activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.ZeroPadding2D((0, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (1, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(11, kernel_initializer='he_normal', activation='softmax')\n",
    "\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08639a-7583-43b5-8486-ce84e5b0fa97",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCAv8KUunyZQ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0b531-f4d3-497e-93f4-d133dffdcac4",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRK6h3BXXPTh"
   },
   "outputs": [],
   "source": [
    "fed_sparse_categorical_accuracy_1=[]\n",
    "fed_sparse_categorical_accuracy_2=[]\n",
    "fed_sparse_categorical_accuracy_3=[]\n",
    "fed_sparse_categorical_accuracy_4=[]\n",
    "fed_sparse_categorical_accuracy_5=[]\n",
    "fed_loss_1=[]\n",
    "fed_loss_2=[]\n",
    "fed_loss_3=[]\n",
    "fed_loss_4=[]\n",
    "fed_loss_5=[]\n",
    "fed_val_sparse_categorical_accuracy_1=[]\n",
    "fed_val_sparse_categorical_accuracy_2=[]\n",
    "fed_val_sparse_categorical_accuracy_3=[]\n",
    "fed_val_sparse_categorical_accuracy_4=[]\n",
    "fed_val_sparse_categorical_accuracy_5=[]\n",
    "fed_val_loss_1=[]\n",
    "fed_val_loss_2=[]\n",
    "fed_val_loss_3=[]\n",
    "fed_val_loss_4=[]\n",
    "fed_val_loss_5=[]\n",
    "ensemble_test_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c48ac-51ab-489f-ae12-77fc5f536b0a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Enot-OFbhZM"
   },
   "outputs": [],
   "source": [
    "EPOCHS=330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad2167-e2f9-4d0e-ab42-695277b38a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    start_time_2 = time.time()\n",
    "    state_1, metrics_1 = federated_learning_iterative_process_1.next(state_1, federated_data)\n",
    "    test_metrics_1 = evaluation_1(state_1.model, [test_dataset_central[0],test_dataset_central[0]])\n",
    "    print('model {}, round  {}, fed_loss: {} - fed_sparse_categorical_accuracy: {} - fed_val_loss: {}- fed_val_sparse_categorical_accuracy: {}'.format(1,n+1, metrics_1[1], metrics_1[0], test_metrics_1[1], test_metrics_1[0] ))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "    \n",
    "    start_time_2 = time.time()\n",
    "    state_2, metrics_2 = federated_learning_iterative_process_2.next(state_2, federated_data)\n",
    "    test_metrics_2 = evaluation_2(state_2.model, [test_dataset_central[0],test_dataset_central[0]])\n",
    "    print('model {}, round  {}, fed_loss: {} - fed_sparse_categorical_accuracy: {} - fed_val_loss: {}- fed_val_sparse_categorical_accuracy: {}'.format(2,n+1, metrics_2[1], metrics_2[0], test_metrics_2[1], test_metrics_2[0] ))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "    \n",
    "    start_time_2 = time.time()\n",
    "    state_3, metrics_3 = federated_learning_iterative_process_3.next(state_3, federated_data)\n",
    "    test_metrics_3 = evaluation_3(state_3.model, [test_dataset_central[0],test_dataset_central[0]])\n",
    "    print('model {}, round  {}, fed_loss: {} - fed_sparse_categorical_accuracy: {} - fed_val_loss: {}- fed_val_sparse_categorical_accuracy: {}'.format(3,n+1, metrics_3[1], metrics_3[0], test_metrics_3[1], test_metrics_3[0] ))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "    \n",
    "    start_time_2 = time.time()    \n",
    "    state_4, metrics_4 = federated_learning_iterative_process_4.next(state_4, federated_data)\n",
    "    test_metrics_4 = evaluation_4(state_4.model, [test_dataset_central[0],test_dataset_central[0]])\n",
    "    print('model {}, round  {}, fed_loss: {} - fed_sparse_categorical_accuracy: {} - fed_val_loss: {}- fed_val_sparse_categorical_accuracy: {}'.format(4,n+1, metrics_4[1], metrics_4[0], test_metrics_4[1], test_metrics_4[0] ))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "    \n",
    "    start_time_2 = time.time()    \n",
    "    state_5, metrics_5 = federated_learning_iterative_process_5.next(state_5, federated_data)\n",
    "    test_metrics_5 = evaluation_5(state_5.model, [test_dataset_central[0],test_dataset_central[0]])\n",
    "    print('model {}, round  {}, fed_loss: {} - fed_sparse_categorical_accuracy: {} - fed_val_loss: {}- fed_val_sparse_categorical_accuracy: {}'.format(5,n+1, metrics_5[1], metrics_5[0], test_metrics_5[1], test_metrics_5[0] ))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "    \n",
    "    start_time_2 = time.time()\n",
    "    fed_sparse_categorical_accuracy_1.append(metrics_1[0])\n",
    "    fed_sparse_categorical_accuracy_2.append(metrics_2[0])\n",
    "    fed_sparse_categorical_accuracy_3.append(metrics_3[0])\n",
    "    fed_sparse_categorical_accuracy_4.append(metrics_4[0])\n",
    "    fed_sparse_categorical_accuracy_5.append(metrics_5[0])\n",
    "    \n",
    "    fed_loss_1.append(metrics_1[1])\n",
    "    fed_loss_2.append(metrics_2[1])\n",
    "    fed_loss_3.append(metrics_3[1])\n",
    "    fed_loss_4.append(metrics_4[1])\n",
    "    fed_loss_5.append(metrics_5[1])\n",
    "\n",
    "    \n",
    "    fed_val_sparse_categorical_accuracy_1.append(test_metrics_1[0])\n",
    "    fed_val_sparse_categorical_accuracy_2.append(test_metrics_2[0])\n",
    "    fed_val_sparse_categorical_accuracy_3.append(test_metrics_3[0])\n",
    "    fed_val_sparse_categorical_accuracy_4.append(test_metrics_4[0])\n",
    "    fed_val_sparse_categorical_accuracy_5.append(test_metrics_5[0])\n",
    "    \n",
    "    fed_val_loss_1.append(test_metrics_1[1]) \n",
    "    fed_val_loss_2.append(test_metrics_2[1]) \n",
    "    fed_val_loss_3.append(test_metrics_3[1]) \n",
    "    fed_val_loss_4.append(test_metrics_4[1]) \n",
    "    fed_val_loss_5.append(test_metrics_5[1]) \n",
    "    \n",
    "    tffweights_1 = tff.learning.model_utils.ModelWeights.from_tff_result(state_1.model)\n",
    "    tffweights_2 = tff.learning.model_utils.ModelWeights.from_tff_result(state_2.model)\n",
    "    tffweights_3 = tff.learning.model_utils.ModelWeights.from_tff_result(state_3.model)\n",
    "    tffweights_4 = tff.learning.model_utils.ModelWeights.from_tff_result(state_4.model)\n",
    "    tffweights_5 = tff.learning.model_utils.ModelWeights.from_tff_result(state_5.model)\n",
    "    \n",
    "    tffweights_1.assign_weights_to(federated_model_1)\n",
    "    tffweights_2.assign_weights_to(federated_model_2)\n",
    "    tffweights_3.assign_weights_to(federated_model_3)\n",
    "    tffweights_4.assign_weights_to(federated_model_4)\n",
    "    tffweights_5.assign_weights_to(federated_model_5)\n",
    "\n",
    "    y_pred_1_test = federated_model_1.predict(x_test)\n",
    "    y_pred_3_test = federated_model_3.predict(x_test)\n",
    "    y_pred_2_test = federated_model_2.predict(x_test)\n",
    "    y_pred_4_test = federated_model_4.predict(x_test)\n",
    "    y_pred_5_test = federated_model_5.predict(x_test)\n",
    "    \n",
    "    y_pred_bool_1_test = np.argmax(y_pred_1_test, axis=1)\n",
    "    y_pred_bool_2_test = np.argmax(y_pred_2_test, axis=1)\n",
    "    y_pred_bool_3_test = np.argmax(y_pred_3_test, axis=1)\n",
    "    y_pred_bool_4_test = np.argmax(y_pred_4_test, axis=1)\n",
    "    y_pred_bool_5_test = np.argmax(y_pred_5_test, axis=1)\n",
    "    \n",
    "    y_pred_test_total=[]\n",
    "    \n",
    "    for i in np.arange(0, len(y_pred_bool_1_test), 1):\n",
    "      listnew=[]\n",
    "      listnew.append(y_pred_bool_1_test[i])\n",
    "      listnew.append(y_pred_bool_2_test[i])\n",
    "      listnew.append(y_pred_bool_3_test[i])\n",
    "      listnew.append(y_pred_bool_4_test[i])\n",
    "      listnew.append(y_pred_bool_5_test[i])\n",
    "      y_pred_test_total.append(Counter(listnew).most_common()[0][0])\n",
    "  \n",
    "    y_pred_test_total=np.array(y_pred_test_total)\n",
    "    y_test_bool = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    ensemble_test_accuracy.append(classification_report(y_test_bool, y_pred_test_total, output_dict=True)['accuracy'])\n",
    "\n",
    "    print('model -ensemble, round  {}, - fed_val_sparse_categorical_accuracy: {}'.format(n+1, ensemble_test_accuracy[n] ))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a5c9c-7f13-42b5-9d8c-2a44622f1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() # create a new figure with a default 111 subplot\n",
    "ax.plot(t, fed_val_sparse_categorical_accuracy_1,'b-',t,fed_val_sparse_categorical_accuracy_2,'g-',t,fed_val_sparse_categorical_accuracy_3,'r-',t,fed_val_sparse_categorical_accuracy_4,'c-',t, fed_val_sparse_categorical_accuracy_5,'-m',t,ensemble_test_accuracy,'k')\n",
    "plt.legend([r'$M_1$',r'$M_2$',r'$M_3$',r'$M_4$',r'$M_5$',r'$M_E$'])\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "axins = zoomed_inset_axes(ax, 4, loc=8, bbox_to_anchor=(230,0,1,1), borderpad=6) # zoom-factor: 2.5, location: upper-left\n",
    "axins.plot(t, fed_val_sparse_categorical_accuracy_1,'b-',t,fed_val_sparse_categorical_accuracy_2,'g-',t,fed_val_sparse_categorical_accuracy_3,'r-',t,fed_val_sparse_categorical_accuracy_4,'c-',t, fed_val_sparse_categorical_accuracy_5,'-m',t,ensemble_test_accuracy,'k')\n",
    "x1, x2, y1, y2 = 280, 330, 0.80, 0.855 # specify the limits\n",
    "\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "axins.set_xlim(x1, x2) # apply the x-limits\n",
    "axins.set_ylim(y1, y2) # apply the y-limits\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f81926-c7eb-49b1-b290-453a18e289eb",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <img src=\"results.png\" width=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2028ae6-8de7-4651-827b-45408cc31a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dle",
   "language": "python",
   "name": "dle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
